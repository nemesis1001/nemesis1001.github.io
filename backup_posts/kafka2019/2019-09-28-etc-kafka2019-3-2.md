---
layout: post
title:  "[More Kafka]3-2. 카프카 프로듀서 실습 추가"
subtitle:   "[More Kafka]3-2. 카프카 프로듀서 실습 추가"
description : "[More Kafka]3-2. 카프카 프로듀서 실습 추가"
keywords : "msa, kafka, zookeeper, 주키퍼, 카프카, 도커, 주키퍼 도커 설치, 카프카 도커, 주키퍼 docker compose, 카프카 docker compose, 도커로 주키퍼 카프카 설치, docker compose zookeeper, docker compose kafka, 컨플루언트, confluent, kafka multi node, 카프카 프로듀서, producer, kafka producer, spring cloud stream binder kafka"
categories: etc
tags: kafka
comments: true
---

### topic, key, value 를 지정하는 경우
> topic:  partition4  
> number of partitions: 4
> number of replication factor: 3

![](https://github.com/twowinsh87/twowinsh87.github.io/blob/master/assets/kafka_img/kafka2019-producer-topic-partition4.png?raw=true)

### 보내는 시나리오
-  key를 지정해서 메세지를 연속적으로 전송
	- key: partitions
	- value: M1, M2, M3, M4
- key를 지정하지 않고 메세지를 전송
	- key: null
	- value: M5

### 결과 미리보기

![](https://github.com/twowinsh87/twowinsh87.github.io/blob/master/assets/kafka_img/kafka2019-producer-topic-partition4-architecture.jpeg?raw=true)


## Codes
-  (1) key를 지정해서 메세지를 연속적으로 전송

```java
Properties kafkaProps = new Properties();  
kafkaProps.put("bootstrap.servers", "kafka:9092,kafka:9093,kafka:9094");  
kafkaProps.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");  
kafkaProps.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");  
Producer<String, String> producer = new KafkaProducer<String, String>(kafkaProps);

ProducerRecord<String, String> record =  
         new ProducerRecord<>("partition4", "partitions", "M1");  // M2, M3, M4 를 보냄.
  producer.send(record, new DemoProducerCallback());  
  log.info("전송완료. record: {}", record);  
  producer.close();
}
```

- `동일한 key 값의 경우에는 해시 알고리즘에 의해서 동일한 파티션으로 분류되어 적재가 된다.`
![](https://github.com/twowinsh87/twowinsh87.github.io/blob/master/assets/kafka_img/kafka2019-producer-m1.png?raw=true)
![](https://github.com/twowinsh87/twowinsh87.github.io/blob/master/assets/kafka_img/kafka2019-producer-m2.png?raw=true)
![](https://github.com/twowinsh87/twowinsh87.github.io/blob/master/assets/kafka_img/kafka2019-producer-m3.png?raw=true)
![](https://github.com/twowinsh87/twowinsh87.github.io/blob/master/assets/kafka_img/kafka2019-producer-m4.png?raw=true)



- (2) Cli에서 key값을 주지 않고 그대로 전송
```bash
➜  bin ./kafka-console-producer.sh --broker-list kafka:9092,kafka:9093,kafka:9094 --topic partition4
> M5
```

```bash
➜  partition4-2 cat 00000000000000000000.log
:��Om���m�����������������M5%
```
- 각 브로커의 파티션의 log 들을 찾아보니 partition2 에 분배된 것을 확인했다. (컨슈밍을 하면 metadata를 얻어서 해당 밸류의 파티션 정보를 알 수 있음.)
- `라운드 로빈` 방식에 의해서 적절하게 분배되어서 들어간다. (카프카 매니저에서 확인이 가능하다. )

### 번외(Spring cloud stream binder kafka 로 전송)
- [코드참고 springkafka03]([https://github.com/twowinsh87/spring-kafka2019/tree/master/springkafka03](https://github.com/twowinsh87/spring-kafka2019/tree/master/springkafka03))
- 이 후 위 프로듀서 코드에서 M6, M7을 순차적으로 보내며 파티션 분배를 검증해봄 M6 - partition-0, M7 partition-2 로 각각 따로 저장됨.
```bash
➜  partition4-0 cat 00000000000000000000.log
��7m�pKm�pK���������������${"partition":"M6"}contentType$"application/json"0spring_json_header_typesD{"contentType":"java.lang.String"}%

➜ partition4-2 cat 00000000000000000000.log
:��Om���m�����������������M5�PK�~m���m������������������${"partition":"M7"}contentType$"application/json"0spring_json_header_typesD{"contentType":"java.lang.String"}%
```
