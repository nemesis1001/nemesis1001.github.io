---
layout: post
title:  "[AWS]EMR 알아보기, 설정 및 운영 팁"
subtitle:   "[AWS]EMR 알아보기, 설정 및 운영 팁"
description : "AWS에서 Spark를 활용한 Pipeline 구축하기"
keywords : "AWS, EMR, EMR이란, zeppelin, ganglia, EMR셋팅, 하둡에코시스템, S3"
categories: data
tags: fcaws
comments: true
---

# Spark을 활용한 데이터 파이프라인 만들기_3주차_이론/실습


> ### 목표
> EMR 구조에 대한 이해 및 실습  
> qaruet

### EMR에 앞서서 parquet?
- 파케이는 넷플릭스가 주도한 데이터 타입이다
- 넷플릭스는 심지어 스크린 하나하나 분석하고, 이 파케이는 굉장히 유용하게 쓰이는 타입이다. (나중에 파케이에 대해서 정리 할 예정)


### AWS EMR이란?
- 쉽게 설명하면 하둡(map reduce) 작업 클러스터가 구축되어있다고 생각해도 된다.
- 그러나 생각보다 많은 서비스를 AWS에서 제공하고 있음
- 정의하면  빅데이터 프레임워크 실행을 간소화하는 관리형 클러스터 플랫폼

<br>

### Master Node, Core Node, Task Node 알아보기
- Master는 1대. Worker에 일함. 통상 맵리듀스에서 Worker라고 불리는 것이 EMR에서 Core와 Task로 나뉨
- 참고로 core task를 이해해야하는 것이 중요하다. 저 부부분이 무너지면 EMR이 전부 꺼져버릴 수 있음.

- Core, Task: map reduce작업을 수행하는데, Task가 map, Core가 Reduce 작업을 하는 것으로 추정
- **가정이지만, core값을 2개로 주다가 1개로 바꾸는 경우에 1대가 2대가 처리하던 Temporary를 수용하지 못할 수 있음. 그러면 Working 상태로 빠지게 되므로 수를 바꾸는 경우에 주의하자**
- 하지만, Task는 100개를 쓰다가 0대로 바꾸어도 아무 문제가 없다.

<br>

### EMR에서 HDFS를 S3로 사용하자 왜?
- 클러스터를 종료하고 실행 후에  데이터를 있는데 전혀 문제없다
- 공간 확장에 대한 신경을 쓰지 않아도 된다.
- 즉, 서버를 하루종일 켜놓을 필요가 없음
- EMR 여러대에서 S3에 접근할 수 있다. 즉 여러대가 하나의 저장 공간을 바라보는데 쉽다 = 데이터 공유 작업에 유리
- 유일한 단점: S3는 마운트 시키는 리모트 디스크로 약간 느리다.

<br>

### EMR의 하둡 에코시스템은 풍부하다
- 다양한 에코시스템을 유기적으로 셋팅하는 것은 힘들다
- 전문가도 1~2달은 걸릴 것
- 5,6분이면 셋팅되는 환경과 저렴한 비용이 장점이다.
- EMR에서 지원하는 하둡에코시스템 들은 사이트에서 확인.
	- 아는 것만 나열해보면 oozie, hue, mahout, R, Spark, hadoop, Hbase, hive, ganglia, Tensorflow, Hive, Pig Tez, presto, flume

<br>

### EMR을 셋팅하자
- 수업 자료는 비공개 입니다. 셋팅관련 질문을 메일 주시면 아는 부분까지 답변드리겠습니다.
- [EMR 셋팅 운영 바로가기](~~~~~~주소~)


### EMR 팁-1
- **먼저 가장 중요한 점**
- EMR 작업시에 마스터 -> inbound 규칙을 주어야 합니다.
- inbound rules -> add rule -> Type(ALL TCP) -> souce(My IP)
	- My IP를 반드시 주세요. ANY IP 하는 순간 나도모르게 누군가 나의 EMR 리소스를 갉아먹습니다.
	- 예를 들어서 카페에서 wifi로 작업중이라면 카페 wifi 주소(My IP)를 잡아주고 작업합니다.
- 저의 경우에는 Hadoop, ganglia, hue, spark, zeppelin presto, hive, pig를 사용합니다.
- ganglia는 gui상태에서 hdfs의 각 노드의 상태정보를 알 수 있습니다.
- oozie는 사용하지 않지만 work flow를 관리하는 툴(etl툴: 데이터 처리 선행작업)입니다. hue는 oozie나 hive pig 등을 웹에서 간편하게 사용할 수 있게 해줍니다.
	- oozie에 대해선 잘 모르니 학습 후 다시 정의하겠습니다.
- presto: 페이스북에서 만들었고, 클러스터가 여러개 있어서 별렬쿼리를 날려주며 빠른 것이 장점입니다. 4억건의 간단한 카운트는 5~6분정도 소요됩니다. 또한 visualizing에도 특화되어 있습니다.
- Hive는 느리지만, spark과 연계하면 좋습니다. 만약 파케이를 hive를 통해서 병렬 저장을 하면 빠릅니다.

<br>

> **주의할 점**  
> spark, presto는 메모리를 엄청 잡아 먹습니다.  
> 고로 처음에 셋팅할 때 aws에서 메모리가 큰 인스턴스를 사용합시다.  
> 로컬에서 셋팅하거나 aws emr에서 작업하다가 문제가 생기면, 메모리 문제를 의심합니다. => 실제로 메모리 문제를 겪어봤습니다.  

<br>

### EMR 팁-2
- AWS EMR을 사용한다면, on-demand와 spot을 이해합시다.
- AWS는 유휴장비를 대여해주고, spot 정책을 합니다.
- 그래서 굉장히 저렴한 비용으로 클러스터를 운영할 수 있습니다.
- EMR을 설정하고 마지막에 Purchasing option에서 on-demand과 spot을 설정할 수 있습니다.
	- on-demand: 정상 금액으로 사용.
	- spot: 사용 금액을 제안, 혹은 할인된 가격에 사용.
		- spot은 bidding, 내가 제안한 금액에 이용하다가 누군가 그 상위의 금액을 사용한다면, 빌린 시스템을 더 높은 입찰자에게 제공합니다 = 내껀 사라짐
		- **그러니 Task node 같은 경우를 spot으로 사용하는 것도 비용을 절감하는 팁이 되겠습니다**  


### 실습
- 저의 실습은 아래와 같습니다.  
- 이미 수집된 자료 -> EMR의 zeppelin에서 전처리 -> RDB에 적재 -> ganglia로 모니터링
- 추가 셋팅은 zeppelin에 알맞은 DB 커넥터를 설정해야합니다.
- RDB말고 다양하게 실습해봅니다.
