---
layout: post
title:  "[AWS]데이터 파이프라인 1주차-1"
subtitle:   "[AWS]데이터 파이프라인 1주차-1 "
description : "aws로 구축하는 데이터 파이프라인"
keywords : "aws, 클라우드, 데이터파이프라인, bigdata, 빅데이터, ec2"
categories: data
tags: fcaws
comments: true
---

## 데이터 파이프라인의 흐름의 이해
> Apache Spark을 활용한 데이터 파이프라인 구축 프로젝트 Workshop  
> 패스트캠퍼스 직방 데이터 책임자 권낙주 강사님 강의를 정리합니다.    


### 1주차의 목적
- 데이터 파이프라인 흐름에 대해서 이해하고 구성하는데 필요한 패키지의 용도를 알자
- 데이터 파이프라인 관련한 용어들을 살펴보자
- 온프레미스(기존 서버호스팅 방식)과 클라우드 환경에서 데이터 수집 차이를 알자

<br>

### 데이터 파이프라인 구성목적  

- 각 팀의 데이터적 요구사항(use case)에 대한 빠른 대응.
- 지속적이고 에러가 없어야 한다.  
- 시스템적으로 발생하는 문제에 대해서 유연한 Scability 해야 한다.
- Scale Up과 Scale Down이 자유로워야한다  
	- 배치 할 때 서버를 늘렸다가 실제 서비스하는 시간에는 줄임
- 이벤트성 데이터 부하에도 처리가 가능해야 한다.  
	- 회원가입이나 이벤트로 인한 서버 부하 처리 등
- 신규로 추가되는 Biz System에 대해서 빠르게 적용 가능해야 한다.
- 데이터 쌓이는 공간에 문제가 없어야 함.
- 수집데이터에 대한 Format에 대해서 유연성 있게 처리 해주어야 한다.

<br>

### BigData LandScape 2018

<img src="https://github.com/twowinsh87/twowinsh87.github.io/blob/master/assets/fastcamp_awsclass_img/Bigdata_Landscape2018.png?raw=true">  

- ELK  
ELk는 특정 기간을 분석하는데는 좋음(다만 시스템적 요구사항이 많음)  
참고, Logstash: Elasticsearch에 데이터를 넣어주는 역할    

- AWS Redshift: HDFS + RDBMS

- 앞으로 계속 정리할 예정

<br>


### 데이터 파이프라인의 흐름을 이해
<img src="https://github.com/twowinsh87/twowinsh87.github.io/blob/master/assets/fastcamp_awsclass_img/datapipeline-1.png?raw=true">  
참고: 패스트캠퍼스 웹 홈페이지


### 데이터 용어의 이해
- **온프레미스** : 자사에 데이터 센터를 두고 시스템 구축부터 운영까지 하는 형태
	- 자체 구축/운용, 자체 보유 인프라 환경
	- 내부에 구축된 인프라
	- 자사에 데이터센터를 두고 시스템 구축부터 운영까지 수향하는 것
	- 서버, 네트워크 장비를 자사에서 조달하고 구축, 운영하는 형태
	- 클라우드와 반대되는 개념

- **메타데이터** : 데이터에 관한 구조화된 데이터로 즉, 대량의 정보 가운데에서 찾고 있는 정보를 효율적으로 찾아내서 이용하기 위해 '일정한 규칙에 따라 콘텐츠에 대하여 부여되는 데이터'

- **ETL** : 추출 / 변환 / 적재는 컴퓨팅에서 데이터베이스 이용의 한 과정으로 데이터웨어하우스에서 다음과 같다.
	- 데이터 소스로부터 데이터를 추출
	- 조회 / 분석을 목적으로 적절한 포맥하나 구조로 데이터를 저장하기 위해 변환하는 과정을 말함
	- 최종 대상(DW, DM 등)으로 변환 데이터를 적재한다(아무래도 raw데이터보다 크기가 적은 형태. 활용 목적에 따라서 기간으로 분류해 저장하기도 함)

- **메시지 큐 시스템** : 데이터를 전달하는 중간의 역할의 큐형태
	- Producer: 메세지를 생산
	- Consumer: 메세지를 소비
	- 흔히 pub/sub 방식이라 불리우고, 대부분의 메세지 큐에서는 동일한 메세지 처리 매커니즘을 가진다.
	- 메세지큐 시스템들 비교 및 카프카 **[알아보기](https://twowinsh87.github.io/etc/2018/08/07/etc-kafka-8/)**

- **Scale Out/In** : 접속된 서버 대수를 늘려 처리능력을 향상하거나 줄이는 것을 말함  

- **Scale Up/Down** : 서버의 크기를 증가해서 고성능 장비로 대체하는 것  
- **AWS CDN** : CDN을 설정하면 서비스 존( ex)아시아 태평양 )에 copy
- **컴퓨터 클러스터** : 여러 대의 컴퓨터들이 연결되어 하나의 시스템처럼 동작하는 컴퓨터들의 집합

<br>

### AWS 패키지 알아보기

- **ec2(Amazon Elastic Compute Cloud)**
	- 가상 컴퓨팅 환경(인스턴스)
	- 쉽게 말해 CPU, 메모리, 스토리지, 네트워킹 용량등 여러가지 구성을 제공하고 사용자는 이에 맞게 셋팅하여 사용하는 가상 컴퓨터
	- 인스턴스 스토어 볼륨: 임시 데이터를 저장함. 인스턴스 종료 시 삭제
	- Amazon EBS: 영구 스토리지 볼륨에 데이터를 저장
	- 보안 그룹을 사용해 인스턴스 접근을 가능하게 하는 방화벽 설정
	- 태그: 사용자가 생성하여 EC2 리소스에 할당할 수 있는 메타데이터

- **S3**
	- 버킷: Amazon S3에 저장된 객체에 대한 컨테이너로 모든 객체는 어떠한 버킷에 포함된다. 쉽게 말해서 윈도우의 폴더이다.
	- 객체: Amazon S3에 저장되는 기본 객체이다. 객체(객체 데이터 + 메타데이터)
	- 키: 버킷 내에 객체의 고유한 식별자. 버킷 내 모든 객체는 정확히 하나의 키를 가짐. Amazon S3는 "버킷 + 키 + 버전"과 객체 자체 사이의 기본 데이터 맵으로 간주할 수 있다.

- **RDS**  
	- AWS의 관계형 데이터베이스
	- 하드웨어 프로비저닝, 데이터베이스 설정, 패치 및 백업 등 소모적인 관리 작업을 자동화함
	- 지원하는 데이터베이스 엔진
		- Oracle, Mysql, Microsoft SQL Server, PostgreSQL, MariaDB, Aurora

- **API Gateway**
	- 어떤 규모에서든 개발자가 API를 생성, 게시, 유지 관리, 모니터링 및 보호할 수 있게 해주는 AWS 서비스
	- 사용자는 RESTful API를 생성, 구성, 호스팅하여 애플리케이션의 AWS 클라우드 액세스를 지원함
	- 쉽게 말하면 인터넷에서 AWS Service에 접속하기 위한 인터페이스 혹은 관문

- **CloudWatch**
	- AWS 리소스와 AWS에서 실시간으로 실행 중인 애플리케이션을 모니터링
	- 리소스 및 애플리케이션에 대해 측정할 수 있는 변수인 지표를 수집하고 추적할 수 있다
	- 정의한 기준으로 경보(알림)을 보내거나 리소스를 자동으로 변경할 수 있다

<br>


> #### 파이프라인 구성 팁
> 데이터 저장할 때: 반드시 압축, text 데이터의 경우에는 70~90% 압축률을 보임
